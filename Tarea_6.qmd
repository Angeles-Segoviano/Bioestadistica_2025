---
title: "Tarea 6. Estimación por el Método de Momentos"
lang: es
format:
  html:
    toc: false
    theme: cosmo
    code-fold: true
    fig-width: 6
    fig-height: 4
    fontsize: 1.1rem
    grid:
      sidebar-width: 250px
      body-width: 950px
      margin-width: 250px
      gutter-width: 1.5rem
---

```{=html}
<style>
main.content {
text-align: justify}
</style>
```

```{r}
#| include: false

library(tidyverse)
library(knitr)
library(kableExtra)
library(readxl)
library(RColorBrewer)
```



Suponiendo dada una muestra aleatoria de tamaño $n$ para cada una de las siguientes distribuciones realiza lo siguiente:

a) Encuentra el estimador para $\theta$ por el método de momentos.

b) Verifica si es insesgado y/o asintóticamente insesgado.
   
   En este inciso será de utilidad recordar la esperanza de la media muestral:
   
$$E(\overline{X}) = E\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n}\sum_{i=1}^n E(X_i) = \frac{1}{n} n E(X) = E(X).$$


c) Calcula la varianza del estimador.

   Es conveniente recordar algunas propiedades de la varianza que se enuncian en la siguiente proposición:

::: {#prp-varianza}

Sean $X$ y $Y$ dos variables aleatorias con varianza finita y sea $c$ una constante, entonces:

1. $Var(c)=0$.
2. $Var(cX) = c^2 Var(X)$.
3. $Var(X+c) = Var(X)$.
4. $Var(X) = E(X^2) - [E(X)]^2$.
5. $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$, donde 
$$Cov(X,Y) = E[(X - E(X))(Y - E(Y))]$$ 
es la covarianza entre $X$ y $Y$. Si $X$ y $Y$ son independientes, entonces $Cov(X,Y) = 0$ y por lo tanto $Var(X+Y) = Var(X) + Var(Y)$.

:::

Además, dado que en una muestra aleatoria consideramos variables aleatorias independientes:

$$Var{\overline{X}} = Var\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n^2}Var\left(\sum_{i=1}^n X_i\right) = \frac{1}{n^2}\sum_{i=1}^n Var(X_i) = \frac{1}{n^2} n Var(X) = \frac{Var(X)}{n}.$$

d) Calcula el error cuadrático medio (ECM).

e) Elige un valor para $\theta$ y simula una muestra aleatoria de tamaño $n=1000$. Calcula el estimador y para los ejercicios 1 al 4 (distribuciones discretas): genera una muestra aleatoria de tamaño $n=1000$ utilizando el valor estimado del parámetro y compara ambos histogramas. Para los ejercicios 5 al 8 (distribuciones continuas): compara el histograma de los valores simulados con el valor real del parámetro y la función de densidad obtenida con el valor estimado del parámetro.

f) Verifica la convergencia del estimador al aumentar el tamaño cada muestra. Grafica los valores del estimador en función del tamaño de la muestra (puede ser por medio de un boxplot).

::: {#exr-discreta_1}

Para $0 < \theta < 4$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta/4 & \text{si } x = 1, \\
1 - \theta/4 & \text{si } x = 2, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

:::

::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{equation}
E(X) = 1 * (\frac{\theta}{4}) + 2 * (1-(\frac{\theta}{4})) = (\frac{\theta}{4}) + 2 - (\frac{\theta}{2}) = 2 - (\frac{\theta}{4})
\end{equation}

Luego, igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{x} = 2 - (\frac{\hat{\theta}}{4}) \implies \hat{\theta} = 4(2 - \overline{x})
\end{equation}

## b) Insesgamiento 

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E\left(4(2 - \overline{x})\right) = 4(2 - E(X)) = 4(2 - (2 - (\frac{\theta}{4}))) = \theta
\end{equation}

Luego, el estimador es insesgado y por lo tanto, asintóticamente insesgado.

## c) Varianza 

Para calcular $Var(X)$ utilizamos la igualdad $Var(X) = E(X^2) - [E(X)]^2$ y para ello, inicialmente calculamos $E(X^2)$:

\begin{equation}
E(X^2) = 1^2 * (\frac{\theta}{4}) + 2^2 * (1 - (\frac{\theta}{4})) = (\frac{\theta}{4}) + 4 - \theta = 4 - (\frac{3\theta}{4}) 
\end{equation}

Luego, calculamos la varianza de $X$:

\begin{equation}
Var(X) = E(X^2) - [E(X)]^2 = \left(4 - \frac{3\theta}{4}\right) - \left(2 - \frac{\theta}{4}\right)^2 = \frac{\theta(4-\theta)}{16}
\end{equation}

Finalmente, Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = \left(\frac{16 * Var(\overline{X})}{n}\right)= \left(\frac{\theta(4-\theta)}{n}\right)
\end{equation}


## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{\theta(4 - \theta)}{n}
\end{equation}

## e) Simulación

Elegimos el valor $\theta=2$ y simulamos una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de probabilidad obtenida con el parámetro estimado. 


```{r}
# Parámetro fijo
theta_fijo_1 <- 2

# Función de probabilidad 
dexr_1 <- function(x, theta){
  ifelse(x == 1, theta/4, ifelse(x == 2, 1 - theta/4, 0))
}

# Función para generar muestra aleatoria
rexr1 <- function(n, theta){
  sample(c(1, 2), size = n, replace = TRUE, prob = c(theta/4, 1 - theta/4))
}

# Función para estimar theta
estimar_theta_1 <- function(X){
  4 * (2 - mean(X))
}

df_ej1 <- data.frame(X = rexr1(1000, theta_fijo_1), Tipo = "Teórico")
theta_hat_1 <- estimar_theta_1(df_ej1$X)
df_temp <- data.frame(X = rexr1(1000, theta_hat_1), Tipo = "Estimado")
df_ej1 <- rbind(df_ej1, df_temp)

library(ggplot2)
ggplot(df_ej1) +
  geom_histogram(aes(x = X, y = after_stat(density), fill = Tipo), 
                 bins = 2, center = 1.5, color = "black", alpha = 0.7, position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Ejercicio 1: Comparación de Histogramas",
       subtitle = paste("θ real =", theta_fijo_1, ", θ estimado =", round(theta_hat_1, 3)),
       x = "Valores", y = "Densidad") +
  theme_bw()
  





```


## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra para $n = 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N = 500$ valores.


```{r}
# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados

df_convergencia_1 <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr1(n, theta_fijo_1)
    estimar_theta_1(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n)
  df_convergencia_1 <- rbind(df_convergencia_1, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia_1) +
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7) +
  geom_hline(yintercept = theta_fijo_1, color = "red", linetype = "dashed", linewidth = 1) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Ejercicio 1: Convergencia del Estimador",
       x = "Tamaño de muestra (n)", y = "Estimación de θ") +
  theme_bw() + theme(legend.position = "none")

```

:::






::: {#exr-discreta_2}

Para $0 < \theta < 6/5$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta/2 & \text{si } x = -1, \\
\theta/3 & \text{si } x = 0, \\
1-5\theta/6 & \text{si } x = 1, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}


::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{equation}
E(X) = \sum_x x f(x;\theta) = (-1)(\theta
/2) + (0)(\theta/3) + (1)(1-5\theta/6) = 1 - \frac{4\theta}{3}
\end{equation}

Luego, igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{X} = 1 - \frac{4\hat\theta}{3} \implies \hat\theta = \frac{3(1 - \bar{X})}{4}
\end{equation}

## b) Insesgamiento 

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E\left(\frac{3(1 - \overline{X})}{4}\right) = \frac{3}{4}(1 - E(\overline{X})) = \frac{3}{4}(1 - E(X)) = \frac{3}{4}\left(1 - \left(1 - \frac{4\theta}{3}\right)\right) = \theta
\end{equation}

Luego, el estimador es insesgado y por lo tanto, asintóticamente insesgado.


## c) Varianza 

Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = Var\left(\frac{3(1 - \overline{X})}{4}\right) = \left(\frac{3}{4}\right)^2 Var(1 - \overline{X}) = \left(\frac{3}{4}\right)^2 Var(\overline{X}) = \left(\frac{3}{4}\right)^2 \frac{Var(X)}{n}
\end{equation}

Para calcular $Var(X)$ utilizamos la igualdad $Var(X) = E(X^2) - [E(X)]^2$ y para ello, inicialmente calculamos $E(X^2)$:

\begin{equation}
E(X^2) = \sum_x x^2 f(x;\theta) = (-1)^2(\theta/2) + (0)^2(\theta/3) + (1)^2(1 - 5\theta/6) = \frac{\theta}{2} + 1 - \frac{5\theta}{6} = 1 - \frac{\theta}{3}
\end{equation}

Luego, calculamos la varianza de $X$:

\begin{equation}
Var(X) = E(X^2) - [E(X)]^2 = \left(1 - \frac{\theta}{3}\right) - \left(1 - \frac{4\theta}{3}\right)^2 = \frac{-\theta^2 + 6\theta}{9}
\end{equation}  

Finalmente, sustituimos $Var(X)$ en la expresión de $Var(\hat\theta)$:

\begin{equation}
Var(\hat\theta) = \left(\frac{3}{4}\right)^2 \frac{1}{n} \frac{-\theta^2 + 6\theta}{9} = \frac{-\theta^2 + 6\theta}{16n}
\end{equation}

## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{-\theta^2 + 6\theta}{16n}
\end{equation}

## e) Simulación

Elegimos el valor $\theta=1$ y simulamos una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de probabilidad obtenida con el parámetro estimado. 


```{r}
# Parámetro fijo
theta_fijo <- 1

# Función de probabilidad 
dexr <- function(x, theta){
f_x <-ifelse(x == -1, theta/2, ifelse(x == 0, theta/3, ifelse(x == 1, 1 - 5*theta/6, 0)))
return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  X <- sample(c(-1, 0, 1), size = n, replace = TRUE, prob = c(theta/2, theta/3, 1 - 5*theta/6))
  return(X)
}

# Función para estimar theta
estimar_theta <- function(X){
  theta_hat <- (3 * (1 - mean(X))) / 4
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(1000, theta_fijo), Tipo = "Teórico")

theta_hat <- estimar_theta(df_exr$X)

df_temp <- data.frame(X = rexr(1000, theta_hat), Tipo = "Estimados")

df_exr <- rbind(df_exr, df_temp)

ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density), fill =Tipo), bins = 3, center = -1, color = "black", alpha = 0.7, position ="dodge")+
  scale_fill_brewer(palette = "Set1")+
  theme_bw()
  





```


## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra para $n = 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N = 500$ valores.


```{r}
# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados

df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = as.factor(n), Estimacion = estimacion_n)
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```

:::


:::



::: {#exr-discreta_3}

Para $0 < \theta < 3/2$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta/3 & \text{si } x = 0, \\
1-2\theta/3 & \text{si } x = 1, \\
\theta/3 & \text{si } x = 2, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}

## a) Estimador

Incialmente calculamos la esperanza de $X$:

\begin{equation}
E(X) = 0 * (\frac{\theta}{3}) + 1 * (1 - (\frac{2\theta}{3})) + 2 * (\frac{\theta}{3}) = 1 - \frac{2\theta}{3} + \frac{2\theta}{3} = 1
\end{equation}

E(X) no depende de $\theta$
Usamos E($X^2$):

\begin{equation}
E(X^2) = 0 + 1 * \left(1 - \frac{2\theta}{3}) + 4 *(\frac{\theta}{3}) =  1 + \frac{2\theta}{3}
\end{equation}

Entonces,

\begin{equation}
\overline{X}^2 = 1 + \frac{2\hat\theta}{3} \implies \hat\theta = 3(\overline{X}^2 - 1)
\end{equation}

Como $E(X) = 1$ no depende de $\theta$, usamos el segundo momento:

$$E(X^2) = 0 + 1 * \left(1 - \frac{2\theta}{3}\right) + 4 * \frac{\theta}{3} = 1 + \frac{2\theta}{3}$$


$$\hat{\theta} = \frac{3(\bar{X}^2 - 1)}{2}$$
## b) Insesgamiento

$$E(\hat{\theta}) = \frac{3}{2}[E(\bar{X}^2) - 1] = \frac{3}{2}[E(X^2) - 1] = \frac{3}{2} * \frac{2\theta}{3} = \theta$$


Si es insesgado. 

## c) Varianza

$$E(X^4) = 0 + 1 * \left(1 - \frac{2\theta}{3}\right) + 16 * \frac{\theta}{3} = 1 + \frac{14\theta}{3}$$


$$\text{Var}(X^2) = \left(1 + \frac{14\theta}{3}\right) - \left(1 + \frac{2\theta}{3}\right)^2 = \frac{\theta(30 - 4\theta)}{9}$$

$$\text{Var}(\hat{\theta}) = \frac{9}{4} * \frac{\text{Var}(X^2)}{n} = \frac{\theta(30 - 4\theta)}{4n}$$


## d) ECM

$$\text{ECM}(\hat{\theta}) = \frac{\theta(30 - 4\theta)}{4n}$$

## e) Simulación

Elegimos el valor $\theta=3$ y simulamos una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con el histograma de los datos simulados con el parámetro estimado. 


```{r}
# Parámetro fijo
theta_fijo_3 <- 1

# Función de probabilidad
dej3 <- function(x, theta){
  ifelse(x == 0, theta/3, ifelse(x == 1, 1 - 2*theta/3, ifelse(x == 2, theta/3, 0)))
}

# Función para generar muestra
rej3 <- function(n, theta){
  sample(c(0, 1, 2), size = n, replace = TRUE, prob = c(theta/3, 1 - 2*theta/3, theta/3))
}

# Función para estimar theta
estimar_theta_3 <- function(X){
  X_squared_mean <- mean(X^2)
  3 * (X_squared_mean - 1) / 2
}

df_ej3 <- data.frame(X = rej3(1000, theta_fijo_3), Tipo = "Teórico")
theta_hat_3 <- estimar_theta_3(df_ej3$X)
df_temp <- data.frame(X = rej3(1000, theta_hat_3), Tipo = "Estimado")
df_ej3 <- rbind(df_ej3, df_temp)

ggplot(df_ej3) +
  geom_histogram(aes(x = X, y = after_stat(density), fill = Tipo), 
                 bins = 3, center = 1, color = "black", alpha = 0.7, position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Ejercicio 3: Comparación de Histogramas",
       subtitle = paste("θ real =", theta_fijo_3, ", θ estimado =", round(theta_hat_3, 3)),
       x = "Valores", y = "Densidad") +
  theme_bw()

```


## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra para $n = 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N = 500$ valores.


```{r}
# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados

df_convergencia_3 <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra

for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rej3(n, theta_fijo_3)
    estimar_theta_3(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n)
  df_convergencia_3 <- rbind(df_convergencia_3, df_temp)
}

# Gráfica de convergencia

ggplot(df_convergencia_3) +
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7) +
  geom_hline(yintercept = theta_fijo_3, color = "red", linetype = "dashed", linewidth = 1) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Ejercicio 3: Convergencia del Estimador",
       x = "Tamaño de muestra (n)", y = "Estimación de θ") +
  theme_bw() + theme(legend.position = "none")

```


:::

:::



::: {#exr-discreta_4}

Para $\theta \in \mathbb{N}$, consideramos la función de probabilidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\frac{2x}{\theta(\theta+1)} & \text{si } x = 1, 2, \ldots, \theta, \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}


::: {.panel-tabset}

## a) Estimador
Incialmente calculamos la esperanza de $X$:

\begin{eqnarray}
E(X) & = & \sum_{x=1}^\theta x\, f(x;\theta)\\
     & = & \frac{2}{\theta(\theta+1)}\sum_{x=1}^\theta x^2\\
     & = & \frac{2\theta +1}{2}

\end{eqnarray}

Ahora, igualamos la esperanza con la media muestral y encontramos el estimador:

\begin{equation}
E(X) = \overline{X} \implies \frac{2\theta +1}{3} = \overline{X}
\implies \hat{\theta} =\frac{3\bar{X}-1}{2}

\end{equation}

## b) Insesgamiento
Verificamos si el estimador es insesgado y/o asintóticamente insesgado.

\begin{eqnarray}
E(\hat{\theta}) & = & E\left(\frac{3\overline{x}}{2}-\frac{1}{2}\right)\\
& = &
\frac{3{2}E(\overline{x})-\frac{1}{2}\\
& = &
\frac{3}{2}\left(\frac{2\theta+1}{3} \right) -\frac{1}{2}\\
& = & \theta
\end{eqnarray}

Luego, el estimador $\hat{\theta}$ es insesgado


## c) Varianza

La varianza del estimador es:

$$var(\hat{\theta})= \frac{\theta^2 +\theta -2}{8n}$$
## d) Error Cuadratico Medio (ECM)

Recordemos que el ECM está dado por:
$$ECM(\hat{\theta})=var(\hat{\theta})+[B(\hat{\theta})]^2$$
Dado que el estimador es insesgado tenemos que $B(\hat{\theta})=0$, luego:
$$ECM(\hat{\theta})= var(\hat{\theta}) = \frac{\theta^2 +\theta -2}{8n}$$


## e) Simulación

Elegimos el valor $\theta=5$ y simulamos una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con el histograma de los datos simulados con el parámetro estimado. 


```{r}
# Parámetro fijo
theta_fijo <- 5

# Función de probabilidad 
dexr <- function(x, theta){
f_x <- 2 * x /(theta * (theta+1))
return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  X <- sample(1:theta, size = n, replace = TRUE, prob = dexr(1:theta, theta))
  return(X)
}

# Función para estimar theta
estimar_theta <- function(X){
  theta_hat <- (3 * mean(X) - 1) / 2
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(1000, theta_fijo), Tipo = "Teórico")

theta_hat <- estimar_theta(df_exr$X)
cat("El valor del estimador es: ", round(theta_hat, 4))

df_temp <- data.frame(X = rexr(1000, theta_hat), Tipo = "Estimados")

df_exr <- rbind(df_exr, df_temp)

ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density), fill =Tipo), bins = theta_fijo, center = 1, color = "black", alpha = 0.7, position ="dodge")+
  scale_fill_brewer(palette = "Set2")+
  scale_x_continuous(breaks = 1:theta_fijo)+
  theme_bw()
  

```


## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra para $n = 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N = 500$ valores.


```{r}
# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados

df_convergencia <- data.frame()

estimaciones_n <- function(n, theta_fijo){
  x <- rexr(n, theta_fijo)
  theta_hat <- estimador_theta(x)
  varianza_teorica <- (theta_fijo)^2 + theta_fijo -2 / (8 * n)
  varianza_muestral <- var(x)
  resultados <- list(theta_hat, varianza_teorica, varianza_muestral)
  return(resultados)
}

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = as.factor(n), Estimacion = estimacion_n)
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```

:::

:::

Para poder generar las muestras aleatorias de las distribuciones continuas de los siguientes ejercicios, es necesario enunciar el siguiente teorema:

::: {#thm-inversion}

Si $X$ es una variable aleatoria continua con función de distribución acumulada $F_X(x)$, entonces la variable aleatoria $U = F_X(X)$ tiene una distribución uniforme en el intervalo $(0,1)$. Además, si $U \sim unif(0,1)$, entonces la variable aleatoria $X = F_X^{-1}(U)$ tiene la misma distribución que $X$. 

:::

Para poder aplicar el teorema de inversión, es necesario encontrar la función de distribución acumulada y su inversa. Para que esto último sea posible, es necesario que la función de distribución acumulada sea estrictamente creciente.


::: {#exr-continua_1}

Para $\theta >0$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\frac{2x}{\theta^2} & \text{si } 0\leq x \leq \theta \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}


::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{eqnarray}
E(X) & = & \int_{-\infty}^{\infty} x f(x;\theta) dx \\
     & = & \int_0^{\theta} x \frac{2x}{\theta^2} dx \\
     & = & \frac{2}{\theta^2} \int_0^{\theta} x^2 dx \\
     & = & \frac{2}{\theta^2} \left[\frac{x^3}{3}\right]_0^{\theta} \\
     & = & \frac{2\theta}{3}
\end{eqnarray}

Ahora igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{X} = \frac{2\hat\theta}{3} \implies \hat\theta = \frac{3\overline{X}}{2}
\end{equation}

## b) Insesgamiento

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E\left(\frac{3\overline{X}}{2}\right) = \frac{3}{2}E(\overline{X}) = \frac{3}{2}E(X) = \frac{3}{2}\left(\frac{2\theta}{3}\right) = \theta
\end{equation}

Entonces, el estimador es insesgado y por lo tanto, asintóticamente insesgado.

## c) Varianza

Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = Var\left(\frac{3\overline{X}}{2}\right) = \left(\frac{3}{2}\right)^2 Var(\overline{X}) = \left(\frac{3}{2}\right)^2 \frac{Var(X)}{n}
\end{equation}

Para calcular $Var(X)$ utilizamos la igualdad $Var(X) = E(X^2) - [E(X)]^2$ y para ello, inicialmente calculamos $E(X^2)$:

\begin{eqnarray}
E(X^2) & = & \int_{-\infty}^{\infty} x^2 f(x;\theta) dx \\
       & = & \int_0^{\theta} x^2 \frac{2x}{\theta^2} dx \\
       & = & \frac{2}{\theta^2} \int_0^{\theta} x^3 dx \\
       & = & \frac{2}{\theta^2} \left[\frac{x^4}{4}\right]_0^{\theta} \\
       & = & \frac{\theta^2}{2}
\end{eqnarray}

Luego, calculamos la varianza de $X$:

\begin{equation}
Var(X) = E(X^2) - [E(X)]^2 = \frac{\theta^2}{2} - \left(\frac{2\theta}{3}\right)^2 = \frac{\theta^2}{18}
\end{equation}


Finalmente, sustituimos $Var(X)$ en la expresión de $Var(\hat\theta)$:

\begin{equation}
Var(\hat\theta) = \left(\frac{3}{2}\right)^2 \frac{1}{n}\frac{\theta^2}{18} = \frac{\theta^2}{8n}
\end{equation}

## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{\theta^2}{8n}
\end{equation}


## e) Simulación

Se elige un valor de $\theta = 5$ y se simula una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de densidad obtenida con el parámetro estimado.

En este caso hay que calcular la función de distribución (CDF o probabilidad acumulada)

\begin{eqnarray}
F_X(x;\theta) & = & \int_{-\infty}^{x} f(t;\theta) dt \\
              & = & \int_0^{x} \frac{2t}{\theta^2} dt \\
              & = & \frac{2}{\theta^2} \left[\frac{t^2}{2}\right]_0^{x} \\
              & = & \frac{x^2}{\theta^2}, \quad 0 \leq x \leq \theta
\end{eqnarray}

Observamos que $F_X(x;\theta)$ es estrictamente creciente en el intervalo $(0, \theta)$ y por lo tanto, podemos encontrar su inversa, igualando $U=F_X(x,\theta)$ donde $U \sim unif(0,1)$, tenemos

\begin{equation}
U = \frac{x^2}{\theta^2} \implies x = \theta \sqrt{U}
\end{equation}

Luego, la variable aleatoria $X=F_X^{-1}(U)=\theta \sqrt{U}$ tiene la misma distribución que $X$.


```{r}
#| fig-align: center

# Parámetro fijo

theta_fijo <- 5

# Función de densidad
dexr <- function(x, theta){
  f_x <- ifelse(x >= 0 & x <= theta, (2*x)/(theta^2), 0)
  return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  U <- runif(n)
  X <- theta * sqrt(U)
  return(X)
}


# Función para estimar theta

estimar_theta <- function(X){
  theta_hat <- (3 * mean(X)) / 2
  return(theta_hat)
}


df_exr <- data.frame(X = rexr(5000, theta_fijo))
theta_hat <- estimar_theta(df_exr$X)


ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density)), binwidth =0.25, color = "black", fill = "coral3", alpha = 0.7, boundary=0)+
  stat_function(fun = dexr, args = list(theta = theta_hat), color = "blue", linewidth = 1, xlim = c(0, theta_hat))+
  annotate("text", x = 4, y = 0.15, label = paste("θ =", round(theta_hat,3)), color = "blue", size = 5)+
  labs(title = "Histograma de datos y función de densidad estimada",
       x = "Valores",
       y = "Densidad")+
  theme_minimal()





```

## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra con $n= 10, 50, 100, 500, 100$. Para cada $n$ se generan $N=500$ valores



```{r}
#| fig-align: "center"

# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados
df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n )
  df_convergencia <- rbind(df_convergencia, df_temp)
}

# Gráfico de convergencia
ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```



:::


:::



::: {#exr-continua_2}

Para $\theta \in \mathbb{R}$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
e^{-(x-\theta)} & \text{si } \theta \leq x < \infty \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

$$E(X) = \int_{\theta}^{\infty} xe^{-(x - \theta)} dx = \theta + 1$$


Ahora igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

$$\hat\theta = \overline{X} - 1$$

## b) Insesgamiento

Verificamos si es insesgado y/o asintóticamente insesgado.

$$E(\hat\theta) = E(\overline{X} - 1 ) = E(X) -1 = (\theta +1) -1 = \theta$$

Entonces, el estimador es insesgado y por lo tanto, asintóticamente insesgado.

## c) Varianza

Calculamos la varianza del estimador.

$$E(X^2) = \int_{\theta}^{\infty} x^2 e^{-(x - \theta)} dx = \theta^2 + 2\theta + 2 $$
$$Var(X) = E(X^2) - [E(X)]^2 = (\theta^2 + 2\theta + 2) - (\theta + 1)^2 = 1$$

$$Var(\hat\theta) = Var(\overline{X}) = \frac{Var(X)}{n} = \frac{1}{n}$$

## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:


$$ECM(\hat\theta) = Var(\hat\theta) = \frac{1}{n}$$


## e) Simulación

Se elige un valor de $\theta = 2$ y se simula una muestra aleatoria de tamaño $n=5000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de densidad obtenida con el parámetro estimado.

```{r}
#| fig-align: center

# Parámetro fijo
theta_fijo_6 <- 2

# Función de densidad
dej6 <- function(x, theta){
  ifelse(x >= theta, exp(-(x - theta)), 0)
}

# Función para generar muestra aleatoria
rej6 <- function(n, theta){
  U <- runif(n)
  X <- theta - log(U)
  return(X)
}

# Función para estimar theta
estimar_theta_6 <- function(X){
  mean(X) - 1
}

# Simulación

df_ej6 <- data.frame(X = rej6(5000, theta_fijo_6))
theta_hat_6 <- estimar_theta_6(df_ej6$X)

ggplot(df_ej6) +
  geom_histogram(aes(x = X, y = after_stat(density)), 
                 binwidth = 0.25, color = "black", 
                 fill = "coral3", alpha = 0.7, boundary = theta_fijo_6) +
  stat_function(fun = dej6, args = list(theta = theta_hat_6), 
                color = "blue", linewidth = 1, xlim = c(theta_hat_6, max(df_ej6$X))) +
  annotate("text", x = theta_hat_6 + 1, y = 0.5, 
           label = paste("θ =", round(theta_hat_6, 3)), 
           color = "blue", size = 5) +
  labs(title = "Ejercicio 6: Histograma de datos y función de densidad estimada",
       x = "Valores", y = "Densidad") +
  theme_minimal()

```
## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra con $n= 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N=500$ valores



```{r}
#| fig-align: "center"

# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados
df_convergencia_6 <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra

for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rej6(n, theta_fijo_6)
    estimar_theta_6(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n)
  df_convergencia_6 <- rbind(df_convergencia_6, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia_6) +
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7) +
  geom_hline(yintercept = theta_fijo_6, color = "red", linetype = "dashed", linewidth = 1) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Ejercicio 6: Convergencia del Estimador",
       x = "Tamaño de la muestra (n)", y = "Estimación de θ") +
  theme_bw() + theme(legend.position = "none")
```

:::

:::



::: {#exr-continua_3}

Para $\theta >0$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\theta x^{\theta-1} & \text{si } 0< x < 1 \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}

::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

$$E(X) = \int_{0}^{1} x \cdot \theta x^{\theta - 1} dx = \int_{0}^{1} x \cdot \theta x^{0} dx = \frac {\theta}{\theta + 1}$$


Ahora igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

$$\hat\theta = \frac{\overline{X}}{1-\overline{X}}$$

## b) Insesgamiento

Verificamos si es insesgado y/o asintóticamente insesgado.

$$E(\hat\theta) = E\left(\frac{\overline{X}}{1-\overline{X}}\right)$$

Entonces, el estimador es asimétricamente sesgado para muestras finitas, pero es asintóticamente insesgado.

## c) Varianza

Calculamos la varianza del estimador.

$$E(X^2) = \int_{0}^{1} x^2 \cdot \theta x^{\theta - 1} dx = \frac{\theta}{\theta + 2 }$$
$$Var(X) = E(X^2) - [E(X)]^2 = \frac{\theta}{(\theta +1)^2 (\theta +2)} $$

$$Var(\hat\theta) = \frac{(\theta + 1)^4}{\theta^2}\frac{Var(X)}{n} = \frac{(\theta + 1)^2}{n(\theta + 2)}$$

## d) ECM

Calculamos el error cuadrático medio (ECM).



$$ECM(\hat\theta) = Var(\hat\theta) = \frac{(\theta + 1)^2}{n(\theta + 2)}$$


## e) Simulación

Se elige un valor de $\theta = 2$ y se simula una muestra aleatoria de tamaño $n=5000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de densidad obtenida con el parámetro estimado.

```{r}
#| fig-align: center

# Parámetro fijo
theta_fijo_7 <- 2

# Función de densidad
dej7 <- function(x, theta){
  ifelse(x > 0 & x < 1, theta * x^(theta - 1), 0)
}

# Función para generar muestra aleatoria (método de inversión)
rej7 <- function(n, theta){
  U <- runif(n)
  X <- U^(1/theta)
  return(X)
}

# Función para estimar theta
estimar_theta_7 <- function(X){
  X_bar <- mean(X)
  X_bar / (1 - X_bar)
}

# Simulación
set.seed(123)
df_ej7 <- data.frame(X = rej7(5000, theta_fijo_7))
theta_hat_7 <- estimar_theta_7(df_ej7$X)

ggplot(df_ej7) +
  geom_histogram(aes(x = X, y = after_stat(density)), 
                 binwidth = 0.05, color = "black", 
                 fill = "coral3", alpha = 0.7, boundary = 0) +
  stat_function(fun = dej7, args = list(theta = theta_hat_7), 
                color = "blue", linewidth = 1, xlim = c(0, 1)) +
  annotate("text", x = 0.7, y = 2, 
           label = paste("θ =", round(theta_hat_7, 3)), 
           color = "blue", size = 5) +
  labs(title = "Ejercicio 7: Histograma de datos y función de densidad estimada",
       x = "Valores", y = "Densidad") +
  theme_minimal()

```
## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra con $n= 10, 50, 100, 500, 1000$. Para cada $n$ se generan $N=500$ valores



```{r}
#| fig-align: "center"

# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados
df_convergencia_7 <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra

for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rej7(n, theta_fijo_7)
    estimar_theta_7(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n)
  df_convergencia_7 <- rbind(df_convergencia_7, df_temp)
}

# Gráfico de convergencia

ggplot(df_convergencia_7) +
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7) +
  geom_hline(yintercept = theta_fijo_7, color = "red", linetype = "dashed", linewidth = 1) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Ejercicio 7: Convergencia del Estimador",
       x = "Tamaño de la muestra (n)", y = "Estimación de θ") +
  theme_bw() + theme(legend.position = "none")
```

:::


:::


::: {#exr-continua_4}

Para $\theta >0$, consideramos la función de densidad:

\begin{equation}
f(x;\theta) = \begin{cases}
\frac{2(\theta-x)}{\theta^2} & \text{si } 0 < x < \theta \\
0 & \text{en otro caso.}
\end{cases}
\end{equation}



::: {.panel-tabset}

## a) Estimador

Encontramos el estimador para $\theta$ por el método de momentos.

Primero calculamos la esperanza de la variable aleatoria $X$:

\begin{eqnarray}
E(X) & = & \int_0^\theta x f(x;\theta) dx\\
     & = & \int_0^\theta x \frac {2(\theta -x)}{\theta^2} dx
     & = & \frac{\theta}{3}
\end{eqnarray}

Ahora igualamos la esperanza muestral a la esperanza teórica para encontrar el estimador por el método de momentos:

\begin{equation}
\overline{X} = \frac{\hat\theta}{3} \implies \hat\theta = 3 \overline{X}
\end{equation}

## b) Insesgamiento

Verificamos si es insesgado y/o asintóticamente insesgado.

\begin{equation}
E(\hat\theta) = E(3\overline{x}) = 3E(\overline{x})= 3\frac{} = \theta
\end{equation}

Entonces, el estimador es insesgado y por lo tanto, asintóticamente insesgado.

## c) Varianza

Calculamos la varianza del estimador.

\begin{equation}
Var(\hat\theta) = Var(3\overline{X}) = 3^2 Var(\overline{x}) = 9\frac{Var(X)}{n}
\end{equation}

Para calcular $Var(X)$ utilizamos la igualdad $Var(X) = E(X^2) - [E(X)]^2$ y para ello, inicialmente calculamos $E(X^2)$:

\begin{eqnarray}
E(X^2) & = & \int_{-\infty}^{\infty} x^2 f(x;\theta) dx \\
       & = & \int_0^{\theta} x^2 \frac{2\theta-x}{\theta^2} dx \\
       & = & \frac{\theta^2}{6}
\end{eqnarray}

Luego, calculamos la varianza de $X$:

\begin{equation}
Var(X) = E(X^2) - [E(X)]^2 = \frac{\theta^2}{6} - \left(\frac{\theta}{3}\right)^2 = \frac{\theta^2}{18}
\end{equation}


Finalmente, sustituimos $Var(X)$ en la expresión de $Var(\hat\theta)$:

\begin{equation}
Var(\hat\theta) = 9\frac{Var(X)}{n} = \frac{\theta^2}{2n}
\end{equation}

## d) ECM

Calculamos el error cuadrático medio (ECM).

Dado que el estimador es insesgado, el ECM es igual a la varianza:

\begin{equation}
ECM(\hat\theta) = Var(\hat\theta) = \frac{\theta^2}{2n}
\end{equation}


## e) Simulación

Se elige un valor de $\theta = 5$ y se simula una muestra aleatoria de tamaño $n=1000$. Calculamos el estimador, graficamos el histograma de los datos y lo comparamos con la función de densidad obtenida con el parámetro estimado.

En este caso hay que calcular la función de distribución (CDF o probabilidad acumulada)

\begin{eqnarray}
F_X(x;\theta) & = & \int_{0}^{x} f(t;\theta) dt \\
              & = & \int_0^{x} \frac{\theta(\theta-t)}{\theta^2} dt \\
              & = & \frac{2x}{\theta}- \frac{x^2}{theta^2} \\
\end{eqnarray}

Observamos que $F_X(x;\theta)$ es estrictamente creciente en el intervalo $(0, \theta)$ y por lo tanto, podemos encontrar su inversa, igualando $U=F_X(x,\theta)$ donde $U \sim unif(0,1)$, tenemos

\begin{equation}
U = \frac{2x}{\theta}- \frac{x^2}{theta^2} \implies x = \theta - \theta \sqrt{1-U}
\end{equation}

Luego, la variable aleatoria $x=F_X^{-1}(U)=\theta - \theta \sqrt{1-U}$ tiene la misma distribución que $X$.


```{r}
#| fig-align: center

# Parámetro fijo

theta_fijo <- 5

# Función de densidad
dexr <- function(x, theta){
  f_x <- 2 * (theta - x) / theta^2
  return(f_x)
}

# Función para generar muestra aleatoria
rexr <- function(n, theta){
  U <- runif(n)
  X <- theta * (1 - sqrt(1 - U))
  return(X)
}


# Función para estimar theta

estimar_theta <- function(X){
   3 * mean(X)
}


df_exr <- data.frame(X = rexr(5000, theta_fijo))
theta_hat <- estimar_theta(df_exr$X)


ggplot(df_exr)+
  geom_histogram(aes(x = X, y = after_stat(density)), binwidth =0.1, color = "black", fill = "coral3", alpha = 0.7, boundary=0)+
  stat_function(fun = dexr, args = list(theta = theta_hat), color = "blue", linewidth = 1, xlim = c(0, theta_hat))+
  annotate("text", x = theta_hat * 0.7, y = 0.3, label = paste("θ =", round(theta_hat,3)), color = "blue", size = 5)+
  labs(title = "Histograma de datos y función de densidad estimada",
       x = "Valores",
       y = "Densidad")+
  theme_minimal()


```
## f) Convergencia

Verificamos la convergencia del estimador al aumentar el tamaño cada muestra. Graficamos los valores del estimador en función del tamaño de la muestra con $n= 10, 50, 100, 500, 100$. Para cada $n$ se generan $N=500$ valores



```{r}
#| fig-align: "center"

# Tamaños de muestra y número de réplicas
tamano <- c(10, 50, 100, 500, 1000)
N <- 500

# Data frame para almacenar los resultados
df_convergencia <- data.frame()

# Simulación y cálculo del estimador para cada tamaño de muestra
for (n in tamano){
  estimacion_n <- replicate(N, {
    X <- rexr(n, theta_fijo)
    estimar_theta(X)
  })
  df_temp <- data.frame(n = factor(n), Estimacion = estimacion_n )
  df_convergencia <- rbind(df_convergencia, df_temp)
}


# Gráfico de convergencia
ggplot(df_convergencia)+
  geom_boxplot(aes(x = n, y = Estimacion, fill = n), alpha = 0.7)+
  geom_hline(yintercept = theta_fijo, color = "red", linetype = "dashed", linewidth = 1)+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "Convergencia del estimador al aumentar el tamaño de la muestra",
       x = "Tamaño de la muestra (n)",
       y = "Estimación de θ")+
  theme_bw()+
  theme(legend.position = "none")

```


:::


:::


Los siguientes ejercicios requieren el uso de los datos contenidos en el archivo `Tarea_6.xlsx`. 

```{r}
datos <- read_xlsx("./Tarea_6.xlsx")
```





::: {#exr-valores_1}

Las observaciones de la columna `Geometrica` provienen de una distribución geométrica con parámetro $\theta$. Calcula la estimación de $\theta$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

Distribución geométrica con parámetro $p$.

$$E(X) = \frac{1}{p}$$

$$\hat{p} = \frac{1}{X}$$
```{r}
options(warn = -1)

# Extraer columna Geometrica

X_geom <- datos$Geometrica

# Estimar theta por método de momentos

theta_hat_9 <- 1 / mean(X_geom)

# Tabla comparativa

tabla_9 <- data.frame(
  Estadístico = c("Media muestral", "Desv. Est. muestral", "Mínimo", "Máximo", "Tamaño muestra"),
  Valor = c(
    round(mean(X_geom), 4),
    round(sd(X_geom), 4),
    min(X_geom),
    max(X_geom),
    length(X_geom)
  )
)

print("Estadísticas Descriptivas:\n")
print(tabla_9)
print(paste("Parámetro estimado: θ =", round(theta_hat_9, 4)))

# Gráfico: Histograma vs Distribución estimada
ggplot(data.frame(X = X_geom)) +
  geom_histogram(aes(x = X, y = after_stat(density)), 
                 bins = max(X_geom), color = "black", 
                 fill = "coral3", alpha = 0.7) +
  stat_function(fun = function(x) dgeom(round(x) - 1, prob = theta_hat_9), 
                color = "blue", linewidth = 1) +
  annotate("text", x = max(X_geom) * 0.7, y = max(dgeom(1:max(X_geom) - 1, prob = theta_hat_9)) * 0.9, 
           label = paste("θ =", round(theta_hat_9, 4)), 
           color = "blue", size = 5) +
  labs(title = "Ejercicio 9: Distribución Geométrica",
       subtitle = paste("Media muestral =", round(mean(X_geom), 4), 
                       ", θ estimado =", round(theta_hat_9, 4)),
       x = "Valores", y = "Densidad") +
  theme_minimal()
```

Conclusiones:

La distribución de los datos se ajusta a la distribución geométrica,por lo que con la estimación de teta podemos decir que la probabilidad de éxito en cada ensayo es de:

```{r}
cat(round(theta_hat_9, 4))
```

:::


::: {#exr-valores_2}

Las observaciones de la columna `Exp` provienen de una distribución exponencial con parámetro $\theta$. Calcula la estimación de $\theta$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

Para una distribución exponencial con parámetro $\lambda$:
$$E(X) = \frac{1}{\lambda}$$

Por el método de momentos:
$$\hat{\lambda} = \frac{1}{\bar{X}}$$


```{r}

lambda_hat <- 1/mean(datos$Exp)
lambda_hat

ggplot(datos)+
  geom_histogram(aes(Exp, y = after_stat(density)), bins = 50, color = "black", fill = "coral3", alpha = 0.7, boundary=0)+
  stat_function(fun = dexp, args = list(rate = lambda_hat), color = "blue", linewidth = 1)+
  annotate("text", x = 0.75, y = 2, label = paste("λ =", round(lambda_hat, 3)), color = "blue", size = 5)+
  labs(title = "Histograma de datos y función de densidad estimada",
       x = "Valores",
       y = "Densidad")+
  theme_minimal()


```

:::


::: {#exr-valores_3}

Las observaciones de la columna `Normal` provienen de una distribución normal con parámetros $\mu$ y $\sigma^2$. Calcula la estimación de $\mu$ y $\sigma^2$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

Para una distribución normal con parámetros $\mu$ y $\sigma^2$:

$$E(X) = \mu$$

$$\text{Var}(X) = \sigma^2$$

Por el método de momentos:
$$\hat{\mu} = \bar{X}$$
$$\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2$$

```{r}
# Extraer columna Normal
X_norm <- datos$Normal

# Estimar parámetros por método de momentos
mu_hat_11 <- mean(X_norm)
sigma2_hat_11 <- mean((X_norm - mu_hat_11)^2)
sigma_hat_11 <- sqrt(sigma2_hat_11)

# Tabla comparativa
tabla_11 <- data.frame(
  Parámetro = c("μ (Media)", "σ² (Varianza)", "σ (Desv. Est.)", "Mínimo", "Máximo", "Tamaño muestra"),
  Estimado = c(
    round(mu_hat_11, 4),
    round(sigma2_hat_11, 4),
    round(sigma_hat_11, 4),
    round(min(X_norm), 4),
    round(max(X_norm), 4),
    length(X_norm)
  )
)

print("Parámetros Estimados:")
print(tabla_11)

# Gráfico: Histograma vs Distribución estimada
ggplot(data.frame(X = X_norm)) +
  geom_histogram(aes(x = X, y = after_stat(density)), 
                 bins = 40, color = "black", 
                 fill = "coral3", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = mu_hat_11, sd = sigma_hat_11), 
                color = "blue", linewidth = 1) +
  annotate("text", x = mu_hat_11 + 3*sigma_hat_11, 
           y = dnorm(mu_hat_11, mu_hat_11, sigma_hat_11) * 0.8, 
           label = paste("μ =", round(mu_hat_11, 2), "\nσ =", round(sigma_hat_11, 2)), 
           color = "blue", size = 5) +
  labs(title = "Ejercicio 11: Distribución Normal",
       subtitle = paste("μ estimado =", round(mu_hat_11, 4), 
                       ", σ estimado =", round(sigma_hat_11, 4)),
       x = "Valores", y = "Densidad") +
  theme_minimal()
```


:::


::: {#exr-valores_4}

Las observaciones de la columna `Gamma` provienen de una distribución gamma con parámetros $\gamma$ y $\lambda$. Calcula la estimación de $\gamma$ y $\lambda$ por el método de momentos, compara la distribución obtenida con el histograma de los datos y brinda tus conclusiones.

Los estimadores por el método de momentos para los parámetros de una variable aleatoria continua $X\sim gamma(\gamma, \lambda)$ son:

\begin{eqnarray}
\hat{\gamma} & = & \frac{m_1^2}{m_2-m_1^2}\\
\hat{\lambda} & = & \frac{m_1}{m_2-m_1^2}\\
\end{eqnarray}

Donde $m_1$ y $m_2$ son los respectivos momentos muestrales. Encontramos los valores estimados:

```{r}
gamma_hat <- mean(datos$Gamma)^2 / (mean(datos$Gamma^2) - mean(datos$Gamma)^2)

lamda_hat <- mean(datos$Gamma) / (mean(datos$Gamma^2) - mean(datos$Gamma)^2)
```

* $\hat{\gamma} = `r round(gamma_hat, 4)`$

* $\hat{\lambda} = `r round(lambda_hat, 4)`$

Graficamos el histograma de los datos proporcionados y la función de densidad con los valores estimados.

```{r}
ggplot(datos)+
  geom_histogram(aes(x = Gamma, y = after_stat(density)), color="black", fill = "deeppink3", alpha = 0.7)+
  stat_function(fun = dgamma, args = list(shape = gamma_hat, rate = lambda_hat), color = "blue", linewidth = 1)+
  theme_bw()
```


:::

